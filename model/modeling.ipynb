{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f23a233-c305-4a11-aaa4-d110c767d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import isodate\n",
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "46b39112-2364-402c-8d85-0821a217d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df=pd.read_csv(\"final_video_datas.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9eb53a3b-556c-4ee6-82bd-b1a78d30dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7308 entries, 0 to 7307\n",
      "Data columns (total 29 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   title_x             7308 non-null   object \n",
      " 1   video_id            7308 non-null   object \n",
      " 2   published_date      7308 non-null   object \n",
      " 3   thumbnail_url       7308 non-null   object \n",
      " 4   view_count          7308 non-null   float64\n",
      " 5   like_count          7175 non-null   float64\n",
      " 6   comment_count       7121 non-null   float64\n",
      " 7   duration            7308 non-null   float64\n",
      " 8   channel_id          7308 non-null   object \n",
      " 9   subscriber_count    7308 non-null   float64\n",
      " 10  brightness          7308 non-null   float64\n",
      " 11  contrast            7308 non-null   float64\n",
      " 12  dominant_colors     7308 non-null   object \n",
      " 13  thumbnail_size      7308 non-null   object \n",
      " 14  object_labels       7308 non-null   object \n",
      " 15  text_positions      7308 non-null   object \n",
      " 16  person_positions    7308 non-null   object \n",
      " 17  prob_text           7308 non-null   object \n",
      " 18  title_length        7308 non-null   int64  \n",
      " 19  word_count          7308 non-null   int64  \n",
      " 20  emoji_count         7308 non-null   int64  \n",
      " 21  has_emoji           7308 non-null   int64  \n",
      " 22  special_char_count  7308 non-null   int64  \n",
      " 23  is_clickbait        7308 non-null   int64  \n",
      " 24  has_question_mark   7308 non-null   bool   \n",
      " 25  has_exclamation     7308 non-null   bool   \n",
      " 26  top_noun_1          7283 non-null   object \n",
      " 27  top_noun_2          7128 non-null   object \n",
      " 28  top_noun_3          6846 non-null   object \n",
      "dtypes: bool(2), float64(7), int64(6), object(14)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>video_id</th>\n",
       "      <th>published_date</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>subscriber_count</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>special_char_count</th>\n",
       "      <th>is_clickbait</th>\n",
       "      <th>has_question_mark</th>\n",
       "      <th>has_exclamation</th>\n",
       "      <th>top_noun_1</th>\n",
       "      <th>top_noun_2</th>\n",
       "      <th>top_noun_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7308</td>\n",
       "      <td>7308</td>\n",
       "      <td>7308</td>\n",
       "      <td>7308</td>\n",
       "      <td>7.308000e+03</td>\n",
       "      <td>7175.000000</td>\n",
       "      <td>7121.000000</td>\n",
       "      <td>7308.000000</td>\n",
       "      <td>7308</td>\n",
       "      <td>7.308000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>7308.000000</td>\n",
       "      <td>7308.000000</td>\n",
       "      <td>7308.000000</td>\n",
       "      <td>7308.000000</td>\n",
       "      <td>7308.000000</td>\n",
       "      <td>7308</td>\n",
       "      <td>7308</td>\n",
       "      <td>7283</td>\n",
       "      <td>7128</td>\n",
       "      <td>6846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7289</td>\n",
       "      <td>7308</td>\n",
       "      <td>1073</td>\n",
       "      <td>7308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2789</td>\n",
       "      <td>3106</td>\n",
       "      <td>3158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>[12뉴스] 오늘의 주요뉴스 / SBS</td>\n",
       "      <td>t-zwVkTOZA8</td>\n",
       "      <td>2025-03-28</td>\n",
       "      <td>https://i.ytimg.com/vi/t-zwVkTOZA8/maxresdefau...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(' YTN', '@ytnnews24')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>테슬라</td>\n",
       "      <td>버라이어티</td>\n",
       "      <td>하바나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5861</td>\n",
       "      <td>5578</td>\n",
       "      <td>284</td>\n",
       "      <td>101</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.481823e+05</td>\n",
       "      <td>9409.151916</td>\n",
       "      <td>782.451341</td>\n",
       "      <td>925.517378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.517002e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>19.960865</td>\n",
       "      <td>0.351259</td>\n",
       "      <td>0.197729</td>\n",
       "      <td>4.297072</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.460531e+06</td>\n",
       "      <td>29279.895063</td>\n",
       "      <td>3528.673610</td>\n",
       "      <td>709.398507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.908397e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.051113</td>\n",
       "      <td>0.860403</td>\n",
       "      <td>0.398314</td>\n",
       "      <td>3.278131</td>\n",
       "      <td>0.233276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.320000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.280000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.151825e+04</td>\n",
       "      <td>466.500000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.190000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.465250e+05</td>\n",
       "      <td>2099.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.610000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.055885e+05</td>\n",
       "      <td>7457.500000</td>\n",
       "      <td>664.000000</td>\n",
       "      <td>1301.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.880000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.618911e+07</td>\n",
       "      <td>638547.000000</td>\n",
       "      <td>255000.000000</td>\n",
       "      <td>3247.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.880000e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title_x     video_id published_date  \\\n",
       "count                    7308         7308           7308   \n",
       "unique                   7289         7308           1073   \n",
       "top     [12뉴스] 오늘의 주요뉴스 / SBS  t-zwVkTOZA8     2025-03-28   \n",
       "freq                       11            1            221   \n",
       "mean                      NaN          NaN            NaN   \n",
       "std                       NaN          NaN            NaN   \n",
       "min                       NaN          NaN            NaN   \n",
       "25%                       NaN          NaN            NaN   \n",
       "50%                       NaN          NaN            NaN   \n",
       "75%                       NaN          NaN            NaN   \n",
       "max                       NaN          NaN            NaN   \n",
       "\n",
       "                                            thumbnail_url    view_count  \\\n",
       "count                                                7308  7.308000e+03   \n",
       "unique                                               7308           NaN   \n",
       "top     https://i.ytimg.com/vi/t-zwVkTOZA8/maxresdefau...           NaN   \n",
       "freq                                                    1           NaN   \n",
       "mean                                                  NaN  6.481823e+05   \n",
       "std                                                   NaN  1.460531e+06   \n",
       "min                                                   NaN  4.320000e+02   \n",
       "25%                                                   NaN  3.151825e+04   \n",
       "50%                                                   NaN  1.465250e+05   \n",
       "75%                                                   NaN  6.055885e+05   \n",
       "max                                                   NaN  1.618911e+07   \n",
       "\n",
       "           like_count  comment_count     duration              channel_id  \\\n",
       "count     7175.000000    7121.000000  7308.000000                    7308   \n",
       "unique            NaN            NaN          NaN                    2453   \n",
       "top               NaN            NaN          NaN  (' YTN', '@ytnnews24')   \n",
       "freq              NaN            NaN          NaN                     201   \n",
       "mean      9409.151916     782.451341   925.517378                     NaN   \n",
       "std      29279.895063    3528.673610   709.398507                     NaN   \n",
       "min          0.000000       0.000000    60.000000                     NaN   \n",
       "25%        466.500000      62.000000   355.750000                     NaN   \n",
       "50%       2099.000000     205.000000   780.000000                     NaN   \n",
       "75%       7457.500000     664.000000  1301.000000                     NaN   \n",
       "max     638547.000000  255000.000000  3247.000000                     NaN   \n",
       "\n",
       "        subscriber_count  ...   word_count  emoji_count    has_emoji  \\\n",
       "count       7.308000e+03  ...  7308.000000  7308.000000  7308.000000   \n",
       "unique               NaN  ...          NaN          NaN          NaN   \n",
       "top                  NaN  ...          NaN          NaN          NaN   \n",
       "freq                 NaN  ...          NaN          NaN          NaN   \n",
       "mean        1.517002e+06  ...    19.960865     0.351259     0.197729   \n",
       "std         3.908397e+06  ...     9.051113     0.860403     0.398314   \n",
       "min         5.280000e+02  ...     1.000000     0.000000     0.000000   \n",
       "25%         1.190000e+05  ...    14.000000     0.000000     0.000000   \n",
       "50%         4.610000e+05  ...    19.000000     0.000000     0.000000   \n",
       "75%         1.880000e+06  ...    25.000000     0.000000     0.000000   \n",
       "max         1.880000e+08  ...    58.000000     7.000000     1.000000   \n",
       "\n",
       "       special_char_count is_clickbait has_question_mark has_exclamation  \\\n",
       "count         7308.000000  7308.000000              7308            7308   \n",
       "unique                NaN          NaN                 2               2   \n",
       "top                   NaN          NaN             False           False   \n",
       "freq                  NaN          NaN              5861            5578   \n",
       "mean             4.297072     0.057745               NaN             NaN   \n",
       "std              3.278131     0.233276               NaN             NaN   \n",
       "min              0.000000     0.000000               NaN             NaN   \n",
       "25%              2.000000     0.000000               NaN             NaN   \n",
       "50%              4.000000     0.000000               NaN             NaN   \n",
       "75%              6.000000     0.000000               NaN             NaN   \n",
       "max             24.000000     1.000000               NaN             NaN   \n",
       "\n",
       "       top_noun_1  top_noun_2  top_noun_3  \n",
       "count        7283        7128        6846  \n",
       "unique       2789        3106        3158  \n",
       "top           테슬라       버라이어티         하바나  \n",
       "freq          284         101          67  \n",
       "mean          NaN         NaN         NaN  \n",
       "std           NaN         NaN         NaN  \n",
       "min           NaN         NaN         NaN  \n",
       "25%           NaN         NaN         NaN  \n",
       "50%           NaN         NaN         NaN  \n",
       "75%           NaN         NaN         NaN  \n",
       "max           NaN         NaN         NaN  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.info()\n",
    "merge_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ba5b05a-e884-44fc-a3f7-710ad621fa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5863\n",
      "1    1445\n",
      "Name: has_emoji, dtype: int64\n",
      "0    6886\n",
      "1     422\n",
      "Name: is_clickbait, dtype: int64\n",
      "False    5861\n",
      "True     1447\n",
      "Name: has_question_mark, dtype: int64\n",
      "False    5578\n",
      "True     1730\n",
      "Name: has_exclamation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['has_emoji', 'is_clickbait', 'has_question_mark', 'has_exclamation']\n",
    "for col in cat_cols:\n",
    "    print(merge_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "695484bd-4e01-48e6-9cef-28dc03a77793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_by_group_median(df, group_col, target_col):\n",
    "    return df[target_col].fillna(\n",
    "        df.groupby(group_col)[target_col].transform('median')\n",
    "    )\n",
    "\n",
    "# 1. 결측 여부 피처\n",
    "merge_df['like_missing'] = merge_df['like_count'].isnull().astype(int)\n",
    "merge_df['comment_missing'] = merge_df['comment_count'].isnull().astype(int)\n",
    "\n",
    "# 2. 구독자수 구간화 → subscriber_group 컬럼 생성\n",
    "merge_df['subscriber_group'] = pd.qcut(\n",
    "    merge_df['subscriber_count'], \n",
    "    q=5,\n",
    "    labels=False,\n",
    "    duplicates='drop'\n",
    ")\n",
    "\n",
    "# 3. subscriber_group 기준으로 중앙값 채우기\n",
    "merge_df['like_count'] = fill_by_group_median(merge_df, 'subscriber_group', 'like_count')\n",
    "merge_df['comment_count'] = fill_by_group_median(merge_df, 'subscriber_group', 'comment_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e8130dfc-c9e9-4c35-8dc6-afd2de3d9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df['published_date'] = pd.to_datetime(merge_df['published_date'])\n",
    "merge_df['pub_year'] = merge_df['published_date'].dt.year\n",
    "merge_df['pub_month'] = merge_df['published_date'].dt.month\n",
    "merge_df['pub_weekday'] = merge_df['published_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51b10f46-bc45-4cea-8401-2cd17233e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리기반모델 쓰는 경우 생략 가능\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# # 정규화\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_cols = ['like_count', 'comment_count', 'subscriber_count', 'duration', 'brightness', 'contrast']\n",
    "# merge_df[scaled_cols] = scaler.fit_transform(merge_df[scaled_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afabd5-d975-4c6c-9618-075db4e8cd72",
   "metadata": {},
   "source": [
    "### 주요단어 벡터화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba49f2-1ce8-4084-88b2-9fd8ed427399",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a5cae1f5-b0de-4d96-b64d-c71d45954c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. 주요 명사 결합\n",
    "merge_df['nouns_combined'] = merge_df[['top_noun_1', 'top_noun_2', 'top_noun_3']].fillna('').apply(\n",
    "    lambda row: ' '.join([str(noun).strip() for noun in row if str(noun).strip() != '']), axis=1\n",
    ")\n",
    "\n",
    "# 2. TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(merge_df['nouns_combined'])\n",
    "\n",
    "# 3. 전체 단어별 평균 TF-IDF를 계산해 상위 n개 선택\n",
    "tfidf_means = np.asarray(tfidf_matrix.mean(axis=0)).flatten()\n",
    "top_n = 30\n",
    "top_n_indices = np.argsort(tfidf_means)[::-1][:top_n]\n",
    "top_n_features = [tfidf.get_feature_names_out()[i] for i in top_n_indices]\n",
    "\n",
    "# 4. 상위 단어만 선택한 DataFrame 만들기\n",
    "top_n_matrix = tfidf_matrix[:, top_n_indices]\n",
    "top_n_df = pd.DataFrame(top_n_matrix.toarray(), columns=[f\"tfidf_{word}\" for word in top_n_features])\n",
    "\n",
    "# 5. 병합\n",
    "merge_df = pd.concat([merge_df.reset_index(drop=True), top_n_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8623573b-8bc6-4615-8325-54273fd711de",
   "metadata": {},
   "source": [
    "'tfidf_테슬라', 'tfidf_뉴스', 'tfidf_전기차', 'tfidf_닌텐도',\r\n",
    "       'tfidf_아이폰', 'tfidf_스위치', 'tfidf_게임', 'tfidf_경제', 'tfidf_한국',\r\n",
    "       'tfidf_인공', 'tfidf_여행', 'tfidf_버라이어티', 'tfidf_미국', 'tfidf_호텔',\r\n",
    "       'tfidf_일상', 'tfidf_먹방', 'tfidf_운동', 'tfidf_중국', 'tfidf_지능', 'tfidf_갱생',\r\n",
    "       'tfidf_하바나', 'tfidf_메이크업', 'tfidf_트럼프', 'tfidf_머스크', 'tfidf_지금',\r\n",
    "       'tfidf_이유', 'tfidf_토크쇼', 'tfidf_일본', 'tfidf_사람', 'tfidf_패션'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b5aa9-023f-41b0-b347-d9be82cb883a",
   "metadata": {},
   "source": [
    "#### 차원 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "64eb52e5-0b5d-4c92-b197-51e9c9dd3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 기존 TF-IDF 전체 벡터 그대로 사용\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(merge_df['nouns_combined'])\n",
    "\n",
    "# SVD로 차원 축소\n",
    "svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "svd_matrix = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# SVD 결과를 DataFrame으로 변환\n",
    "svd_df = pd.DataFrame(svd_matrix, columns=[f\"tfidf_svd_{i+1}\" for i in range(svd_matrix.shape[1])])\n",
    "\n",
    "# 병합\n",
    "merge_df = pd.concat([merge_df.reset_index(drop=True), svd_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e516c9-ccbb-4085-b85d-03d46e53a512",
   "metadata": {},
   "source": [
    " 'tfidf_svd_1', 'tfidf_svd_2', 'tfidf_svd_3', 'tfidf_svd_4',\r\n",
    "       'tfidf_svd_5', 'tfidf_svd_6', 'tfidf_svd_7', 'tfidf_svd_8',\r\n",
    "       'tfidf_svd_9', 'tfidf_svd_10', 'tfidf_svd_11', 'tfidf_svd_12',\r\n",
    "       'tfidf_svd_13', 'tfidf_svd_14', 'tfidf_svd_15', 'tfidf_svd_16',\r\n",
    "       'tfidf_svd_17', 'tfidf_svd_18', 'tfidf_svd_19', 'tfidf_svd_20'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d54b1f-4f73-485f-ace3-36d02d74022b",
   "metadata": {},
   "source": [
    "## 객체 & 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "add030dc-69a6-4867-bc37-52cf6e4bab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# 문자열을 실제 리스트로 변환 (object_labels 칼럼에만 적용)\n",
    "merge_df['object_labels'] = merge_df['object_labels'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "merge_df['dominant_colors'] = merge_df['dominant_colors'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    return val if isinstance(val, list) else []\n",
    "\n",
    "# 적용\n",
    "merge_df['person_positions'] = merge_df['person_positions'].apply(safe_literal_eval)\n",
    "merge_df['text_positions'] = merge_df['text_positions'].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a6a81d1-9d64-48c4-9659-b6738be8ce25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aliceblue',\n",
       " 'antiquewhite',\n",
       " 'aquamarine',\n",
       " 'azure',\n",
       " 'beige',\n",
       " 'bisque',\n",
       " 'black',\n",
       " 'blanchedalmond',\n",
       " 'blue',\n",
       " 'blueviolet',\n",
       " 'brown',\n",
       " 'burlywood',\n",
       " 'cadetblue',\n",
       " 'chartreuse',\n",
       " 'chocolate',\n",
       " 'coral',\n",
       " 'cornflowerblue',\n",
       " 'cornsilk',\n",
       " 'crimson',\n",
       " 'cyan',\n",
       " 'darkblue',\n",
       " 'darkcyan',\n",
       " 'darkgoldenrod',\n",
       " 'darkgray',\n",
       " 'darkgreen',\n",
       " 'darkgrey',\n",
       " 'darkkhaki',\n",
       " 'darkmagenta',\n",
       " 'darkolivegreen',\n",
       " 'darkorange',\n",
       " 'darkorchid',\n",
       " 'darkred',\n",
       " 'darksalmon',\n",
       " 'darkseagreen',\n",
       " 'darkslateblue',\n",
       " 'darkslategrey',\n",
       " 'darkturquoise',\n",
       " 'darkviolet',\n",
       " 'deeppink',\n",
       " 'deepskyblue',\n",
       " 'dimgrey',\n",
       " 'dodgerblue',\n",
       " 'firebrick',\n",
       " 'floralwhite',\n",
       " 'forestgreen',\n",
       " 'gainsboro',\n",
       " 'ghostwhite',\n",
       " 'gold',\n",
       " 'goldenrod',\n",
       " 'green',\n",
       " 'greenyellow',\n",
       " 'grey',\n",
       " 'honeydew',\n",
       " 'hotpink',\n",
       " 'indianred',\n",
       " 'indigo',\n",
       " 'ivory',\n",
       " 'khaki',\n",
       " 'lavender',\n",
       " 'lavenderblush',\n",
       " 'lawngreen',\n",
       " 'lemonchiffon',\n",
       " 'lightblue',\n",
       " 'lightcoral',\n",
       " 'lightcyan',\n",
       " 'lightgoldenrodyellow',\n",
       " 'lightgray',\n",
       " 'lightgreen',\n",
       " 'lightgrey',\n",
       " 'lightpink',\n",
       " 'lightsalmon',\n",
       " 'lightseagreen',\n",
       " 'lightskyblue',\n",
       " 'lightslategrey',\n",
       " 'lightsteelblue',\n",
       " 'lightyellow',\n",
       " 'lime',\n",
       " 'limegreen',\n",
       " 'linen',\n",
       " 'magenta',\n",
       " 'maroon',\n",
       " 'mediumaquamarine',\n",
       " 'mediumblue',\n",
       " 'mediumorchid',\n",
       " 'mediumpurple',\n",
       " 'mediumseagreen',\n",
       " 'mediumslateblue',\n",
       " 'mediumspringgreen',\n",
       " 'mediumturquoise',\n",
       " 'mediumvioletred',\n",
       " 'midnightblue',\n",
       " 'mintcream',\n",
       " 'mistyrose',\n",
       " 'moccasin',\n",
       " 'navajowhite',\n",
       " 'navy',\n",
       " 'oldlace',\n",
       " 'olive',\n",
       " 'olivedrab',\n",
       " 'orange',\n",
       " 'orangered',\n",
       " 'orchid',\n",
       " 'palegoldenrod',\n",
       " 'palegreen',\n",
       " 'paleturquoise',\n",
       " 'palevioletred',\n",
       " 'papayawhip',\n",
       " 'peachpuff',\n",
       " 'peru',\n",
       " 'pink',\n",
       " 'plum',\n",
       " 'powderblue',\n",
       " 'purple',\n",
       " 'red',\n",
       " 'rosybrown',\n",
       " 'royalblue',\n",
       " 'saddlebrown',\n",
       " 'salmon',\n",
       " 'sandybrown',\n",
       " 'seagreen',\n",
       " 'seashell',\n",
       " 'sienna',\n",
       " 'silver',\n",
       " 'skyblue',\n",
       " 'slateblue',\n",
       " 'slategrey',\n",
       " 'snow',\n",
       " 'springgreen',\n",
       " 'steelblue',\n",
       " 'tan',\n",
       " 'teal',\n",
       " 'thistle',\n",
       " 'tomato',\n",
       " 'turquoise',\n",
       " 'violet',\n",
       " 'wheat',\n",
       " 'white',\n",
       " 'whitesmoke',\n",
       " 'yellow',\n",
       " 'yellowgreen'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_li=[]\n",
    "for i in merge_df['dominant_colors']:\n",
    "    for j in i:\n",
    "        color_li.append(j[0])\n",
    "\n",
    "set(color_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b582edb7-bb8d-4d05-ac05-807bf05fe875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def preprocess_for_model(df, top_tfidf_n=50):\n",
    "    df = df.copy()\n",
    "\n",
    "    color_groups = {\n",
    "        'red': {'red', 'crimson', 'firebrick', 'darkred', 'salmon', 'indianred', 'tomato', 'orangered'},\n",
    "        'blue': {'blue', 'navy', 'dodgerblue', 'deepskyblue', 'royalblue', 'skyblue', 'slateblue', 'mediumblue'},\n",
    "        'green': {'green', 'lime', 'forestgreen', 'seagreen', 'springgreen', 'mediumseagreen', 'darkgreen', 'lawngreen'},\n",
    "        'yellow': {'yellow', 'gold', 'khaki', 'lemonchiffon', 'lightyellow', 'palegoldenrod'},\n",
    "        'purple': {'purple', 'magenta', 'violet', 'orchid', 'mediumorchid', 'mediumpurple', 'darkviolet'},\n",
    "        'brown': {'brown', 'sienna', 'chocolate', 'peru', 'saddlebrown', 'tan', 'burlywood'},\n",
    "        'grey': {'grey', 'gray', 'lightgrey', 'darkgrey', 'dimgrey', 'slategrey', 'gainsboro'},\n",
    "        'white': {'white', 'snow', 'ivory', 'ghostwhite', 'whitesmoke', 'floralwhite', 'seashell'},\n",
    "        'pink': {'pink', 'lightpink', 'hotpink', 'lavenderblush'},\n",
    "        'other': set()\n",
    "    }\n",
    "\n",
    "    def map_color_to_group(color):\n",
    "        for group, colors in color_groups.items():\n",
    "            if color.lower() in colors:\n",
    "                return group\n",
    "        return 'other'\n",
    "\n",
    "    for col in color_groups.keys():\n",
    "        df[f'color_{col}'] = 0.0\n",
    "\n",
    "    def count_color_groups(color_list):\n",
    "        counter = defaultdict(float)\n",
    "        for color, prob in color_list:\n",
    "            group = map_color_to_group(color)\n",
    "            counter[group] += prob\n",
    "        return counter\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if isinstance(row['dominant_colors'], list):\n",
    "            counter = count_color_groups(row['dominant_colors'])\n",
    "            for group in counter:\n",
    "                df.at[idx, f'color_{group}'] = counter[group]\n",
    "\n",
    "    df['person_count'] = df['object_labels'].apply(lambda x: x.count('person') if isinstance(x, list) else 0)\n",
    "\n",
    "    all_objects = []\n",
    "    for x in df['object_labels']:\n",
    "        if isinstance(x, list):\n",
    "            all_objects.extend([obj for obj in x if obj != 'person'])\n",
    "\n",
    "    top_objects = [obj for obj, _ in Counter(all_objects).most_common(10)]\n",
    "\n",
    "    for obj in top_objects:\n",
    "        df[f'obj_{obj}'] = df['object_labels'].apply(lambda x: int(obj in x) if isinstance(x, list) else 0)\n",
    "\n",
    "    df['has_text'] = df['text_positions'].apply(lambda x: int(x != ['텍스트 없음']))\n",
    "    df['has_person_pos'] = df['person_positions'].apply(lambda x: int(x != ['사람 없음']))\n",
    "\n",
    "    # tfidf = TfidfVectorizer(max_features=top_tfidf_n)\n",
    "    # tfidf_matrix = tfidf.fit_transform(df['title_x'].fillna(''))\n",
    "    # tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f'tfidf_{w}' for w in tfidf.get_feature_names_out()])\n",
    "    # df = pd.concat([df.reset_index(drop=True), tfidf_df], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b5d8e009-6e03-416c-933a-8c6d60a1641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = preprocess_for_model(merge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c15bdd9f-f4a2-4141-946c-f80dd3df2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사람 위치\n",
    "model_df['person_left'] = model_df['person_positions'].apply(lambda x: sum('left' in p for p in x))\n",
    "model_df['person_middle'] = model_df['person_positions'].apply(lambda x: sum('middle' in p for p in x))\n",
    "model_df['person_right'] = model_df['person_positions'].apply(lambda x: sum('right' in p for p in x))\n",
    "model_df['person_small'] = model_df['person_positions'].apply(lambda x: sum('s' in p for p in x))\n",
    "model_df['person_medium'] = model_df['person_positions'].apply(lambda x: sum('m' in p for p in x))\n",
    "model_df['person_large'] = model_df['person_positions'].apply(lambda x: sum('l' in p for p in x))\n",
    "\n",
    "# 텍스트 위치\n",
    "model_df['text_left'] = model_df['text_positions'].apply(lambda x: sum('left' in p for p in x))\n",
    "model_df['text_middle'] = model_df['text_positions'].apply(lambda x: sum('middle' in p for p in x))\n",
    "model_df['text_right'] = model_df['text_positions'].apply(lambda x: sum('right' in p for p in x))\n",
    "model_df['text_small'] = model_df['text_positions'].apply(lambda x: sum('s' in p for p in x))\n",
    "model_df['text_medium'] = model_df['text_positions'].apply(lambda x: sum('m' in p for p in x))\n",
    "model_df['text_large'] = model_df['text_positions'].apply(lambda x: sum('l' in p for p in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "cdbf2f8c-2ce1-430d-95d1-4168540026ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns=['view_count',\n",
    "       'like_count', 'comment_count', 'duration',\n",
    "       'subscriber_count', 'brightness', 'contrast', 'title_length', 'word_count', 'emoji_count', 'has_emoji',\n",
    "       'special_char_count', 'is_clickbait', 'has_question_mark',\n",
    "       'has_exclamation', 'pub_year',\n",
    "       'pub_month', 'pub_weekday',\n",
    "       'color_red', 'color_blue', 'color_green', 'color_yellow',\n",
    "       'color_purple', 'color_brown', 'color_grey', 'color_white',\n",
    "       'color_pink', 'color_other', \n",
    "        'person_count',\n",
    "        'obj_bowl', 'obj_없음', 'obj_car', 'obj_tie', 'obj_chair', 'obj_cake', 'obj_cup',\n",
    "       'obj_cell phone', 'obj_bottle', 'obj_teddy bear', \n",
    "        'has_text', 'has_person_pos', 'person_left', 'person_middle', 'person_right',\n",
    "       'person_small', 'person_medium', 'person_large', 'text_left',\n",
    "       'text_middle', 'text_right', 'text_small', 'text_medium', 'text_large']\n",
    "\n",
    "model_df=model_df[model_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4686e769-1e62-41af-8088-8d91b7b6325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_csv('model_datas.csv', index=False, encoding=\"utf-8-sig\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3049cfdf-130e-4890-a16a-c407ced2d910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 655146.30\n",
      "R²: 0.7567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"model_datas.csv\")\n",
    "\n",
    "# 타겟과 피처 분리\n",
    "X = df.drop(columns=[\"view_count\"])\n",
    "y = df[\"view_count\"]\n",
    "\n",
    "# 학습/검증 데이터 나누기\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 선택 및 학습 - RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# 평가\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1b585-456c-429c-863b-ecd8f0160a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
