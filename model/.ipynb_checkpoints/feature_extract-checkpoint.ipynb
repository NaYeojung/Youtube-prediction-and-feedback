{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04140e3d-f268-4ac4-8f75-603bab2cf07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duwjd\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import isodate\n",
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "import easyocr\n",
    "import torch\n",
    "import webcolors\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "829b1b90-9e9a-4d28-a589-a474934ac1a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3324\n",
      "                                               title     video_id  \\\n",
      "0                                  결국 긴팔문신 제거 하는 조두팔  t-zwVkTOZA8   \n",
      "1  [vlog] 고등학교 교사 직장인 브이로그 | 학부모 총회 그리고 상담 가득한 한 ...  AMwSEsFVRGg   \n",
      "2                             오사카&교토 브이로그 • 쇼핑에미띤여자들  PocqBywf0FU   \n",
      "3  마라로제엽떡+닭꼬치 꿀조합•노티드 딸기전메뉴🍓먹고 결국 컵라면2개로 마무리•옛날통닭...  6eNhJ4LYr1k   \n",
      "4  [썰레디윗미] 이젠 말할 수 있다🙄 역대급 똥차 썰 낋여오니라.ㅣ이게 실화라고? 구...  G9tXGudpOCo   \n",
      "\n",
      "  published_date                                      thumbnail_url  \\\n",
      "0       20250328  https://i.ytimg.com/vi/t-zwVkTOZA8/maxresdefau...   \n",
      "1       20250328  https://i.ytimg.com/vi/AMwSEsFVRGg/maxresdefau...   \n",
      "2       20250224  https://i.ytimg.com/vi/PocqBywf0FU/maxresdefau...   \n",
      "3       20250329  https://i.ytimg.com/vi/6eNhJ4LYr1k/maxresdefau...   \n",
      "4       20250328  https://i.ytimg.com/vi/G9tXGudpOCo/maxresdefau...   \n",
      "\n",
      "   view_count  like_count  comment_count duration  \\\n",
      "0    244420.0         NaN          221.0     7:39   \n",
      "1     11267.0       265.0           54.0    18:37   \n",
      "2     12158.0       315.0          110.0    21:46   \n",
      "3     14333.0       441.0           71.0    29:32   \n",
      "4     58409.0         NaN          118.0    18:17   \n",
      "\n",
      "                        channel_id  subscriber_count  \n",
      "0               ('조두팔', '@조두팔이라고')          412000.0  \n",
      "1  ('HappyHojin', '@Happppyhojin')           46500.0  \n",
      "2            ('권예왕왕', '@ye_one_e')           15700.0  \n",
      "3       ('째링', '@buttermellowday')           71700.0  \n",
      "4         ('냔지 nyanji', '@quya_a')          296000.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"video_datas.csv\", encoding=\"utf-8-sig\")\n",
    "#df=df.iloc[:3,:]\n",
    "print(len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef22a070-2522-4060-a28e-b880b5d6b6db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                 0\n",
      "video_id              0\n",
      "published_date        0\n",
      "thumbnail_url         0\n",
      "view_count            0\n",
      "like_count           68\n",
      "comment_count       174\n",
      "duration              0\n",
      "channel_id            0\n",
      "subscriber_count      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "# print(set(df[df['channel_id'].str.contains('none', case=False, na=False)]['channel_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "112cc4de-a590-4591-9ab0-4384d7f794dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남은 데이터 개수: 2540\n"
     ]
    }
   ],
   "source": [
    "# 조회수 낮은 데이터 제거\n",
    "lower_threshold = df[\"view_count\"].quantile(0.05)  # 하위 5%\n",
    "df = df[df[\"view_count\"] > lower_threshold]\n",
    "\n",
    "# 구독자 수 적은 채널 삭제\n",
    "df = df[df[\"subscriber_count\"] > 500]\n",
    "\n",
    "# 5년 이상 된 영상 제거 (현재 날짜 기준)\n",
    "df[\"published_date\"] = pd.to_datetime(df[\"published_date\"])  # 날짜 변환\n",
    "three_years_ago = pd.Timestamp.today() - pd.DateOffset(years=5)\n",
    "df = df[df[\"published_date\"] > three_years_ago]\n",
    "\n",
    "# 업로드된 지 하루밖에 안 된 영상 삭제\n",
    "one_day_ago = pd.Timestamp.today() - pd.DateOffset(days=3)\n",
    "df = df[df[\"published_date\"] < one_day_ago]\n",
    "\n",
    "# 중복 데이터 제거\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 결측값(NaN) 제거\n",
    "# df = df.dropna()\n",
    "\n",
    "# 영상 길이가 1분~60분이 아닌 데이터 삭제 (초 단위 기준)\n",
    "import re\n",
    "\n",
    "def convert_to_seconds(time_str):\n",
    "    parts = list(map(int, re.findall(r'\\d+', time_str)))  # 숫자만 추출\n",
    "    \n",
    "    if len(parts) == 3:  # HH:MM:SS 형식\n",
    "        h, m, s = parts\n",
    "    elif len(parts) == 2:  # MM:SS 형식\n",
    "        h, m, s = 0, parts[0], parts[1]\n",
    "    else:\n",
    "        return np.nan  # 잘못된 형식 처리\n",
    "\n",
    "    return h * 3600 + m * 60 + s  # 초 단위 변환\n",
    "\n",
    "# 변환 적용\n",
    "df[\"duration\"] = df[\"duration\"].astype(str).apply(convert_to_seconds)\n",
    "\n",
    "# 변환 후, 영상 길이가 1분~1시간 범위 내에 있는 데이터만 유지\n",
    "df = df[(df[\"duration\"] >= 60) & (df[\"duration\"] <= 3600)]\n",
    "\n",
    "# 이상치(너무 높은 조회수, 너무 긴 영상) 제거\n",
    "# 조회수 이상치 (상위 1% 이상 제거)\n",
    "upper_threshold_views = df[\"view_count\"].quantile(0.99)\n",
    "df = df[df[\"view_count\"] < upper_threshold_views]\n",
    "\n",
    "# 영상 길이 이상치 (상위 1% 이상 제거)\n",
    "upper_threshold_length = df[\"duration\"].quantile(0.99)\n",
    "df = df[df[\"duration\"] < upper_threshold_length]\n",
    "\n",
    "print(\"남은 데이터 개수:\", len(df))\n",
    "# df.to_csv(\"cleaned_youtube_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e77ae-bd67-46bf-b424-e615f33da7c8",
   "metadata": {},
   "source": [
    "## 썸네일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a161d72-1f26-4035-84d7-28b36f999d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\duwjd/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-3-18 Python-3.11.7 torch-2.6.0+cu118 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "C:\\Users\\duwjd/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\duwjd/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\duwjd/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "# YOLO 모델 로드 (Ultralytics YOLOv5 예제)\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "ocr_reader = easyocr.Reader(['en', 'ko'])  # 영어 & 한글 OCR 지원\n",
    "\n",
    "# 이미지 로드 (URL에서 다운로드)\n",
    "def load_image_from_url(url):\n",
    "    fallback_urls = [\n",
    "        url,\n",
    "        url.replace('maxresdefault', 'sddefault'),\n",
    "        url.replace('sddefault', 'hqdefault'),\n",
    "        url.replace('hqdefault', 'mqdefault'),\n",
    "        url.replace('mqdefault', 'default')\n",
    "    ]\n",
    "\n",
    "    for new_url in fallback_urls:\n",
    "        try:\n",
    "            response = requests.get(new_url, stream=True, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            image = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            if image is not None:\n",
    "                height, width, _ = image.shape\n",
    "                print(f\"이미지를 성공적으로 로드했습니다: {new_url}\")\n",
    "                return image, height, width\n",
    "        except requests.RequestException:\n",
    "            print(f\"이미지 로드 실패: {new_url}\")\n",
    "\n",
    "    raise ValueError(\"모든 URL에서 이미지를 불러올 수 없습니다.\")\n",
    "    \n",
    "# 이미지 전처리 (그레이스케일 + 이진화)\n",
    "def preprocess_image(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    denoised_image = cv2.GaussianBlur(binary_image, (5, 5), 0)\n",
    "    return denoised_image\n",
    "\n",
    "# 텍스트 분석 (OCR)\n",
    "def extract_text(image, confidence_threshold=0.7):\n",
    "    results = ocr_reader.readtext(image)\n",
    "    text_info = []\n",
    "    for (bbox, text, prob) in results:\n",
    "        if prob >= confidence_threshold: \n",
    "            (top_left, _, bottom_right, _) = bbox\n",
    "            x, y = int(top_left[0]), int(top_left[1])\n",
    "            width = int(bottom_right[0] - top_left[0])\n",
    "            height = int(bottom_right[1] - top_left[1])\n",
    "            area = width * height\n",
    "            \n",
    "            text_info.append({\n",
    "                \"text\": text,\n",
    "                \"x\": x, \"y\": y,\n",
    "                \"width\": width, \"height\": height,\n",
    "                \"area\": area,\n",
    "                \"probability\": prob \n",
    "            })\n",
    "    return text_info\n",
    "\n",
    "# 객체 탐지 (YOLO)\n",
    "def detect_objects(image):\n",
    "    if image is None:\n",
    "        return {\"objects\": [], \"central_focus\": False}\n",
    "    \n",
    "    results = yolo_model(image)\n",
    "    objects = []\n",
    "    central_focus = False\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    for result in results.xyxy[0]:  # YOLOv5 결과\n",
    "        x1, y1, x2, y2, conf, cls = map(int, result[:6])\n",
    "        label = yolo_model.names[cls]\n",
    "        \n",
    "        # 객체의 중앙 여부 확인\n",
    "        obj_center_x = (x1 + x2) / 2\n",
    "        obj_center_y = (y1 + y2) / 2\n",
    "        if (width * 0.3) < obj_center_x < (width * 0.7) and (height * 0.3) < obj_center_y < (height * 0.7):\n",
    "            central_focus = True\n",
    "        \n",
    "        objects.append({\"label\": label, \"x\": x1, \"y\": y1, \"width\": x2-x1, \"height\": y2-y1})\n",
    "    \n",
    "    return {\"objects\": objects, \"central_focus\": central_focus}\n",
    "\n",
    "\n",
    "# 주요 색상 추출 및 이름 변환\n",
    "def closest_colour(requested_colour):\n",
    "    \"\"\"주어진 RGB 값과 가장 가까운 CSS3 색상명을 찾음\"\"\"\n",
    "    min_colours = {}\n",
    "    for name in webcolors.names(\"css3\"):\n",
    "        r_c, g_c, b_c = webcolors.name_to_rgb(name)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "\n",
    "def get_color_name_from_rgb(r, g, b):\n",
    "    \"\"\"정확한 색상이 있으면 반환, 없으면 가장 가까운 색상명 반환\"\"\"\n",
    "    try:\n",
    "        return webcolors.rgb_to_name((r, g, b), spec='css3')\n",
    "    except ValueError:\n",
    "        return closest_colour((r, g, b))\n",
    "\n",
    "def extract_colors(image, num_colors=5):\n",
    "    \"\"\"이미지에서 주요 색상을 추출하고, 각 색상의 비율을 반환\"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).reshape((-1, 3))\n",
    "    kmeans = KMeans(n_clusters=num_colors, n_init=\"auto\")\n",
    "    labels = kmeans.fit_predict(image)\n",
    "    palette = kmeans.cluster_centers_.astype(int)\n",
    "    \n",
    "    # 색상의 출현 빈도 계산\n",
    "    counter = np.bincount(labels)\n",
    "    total_count = np.sum(counter)\n",
    "    # 주요 색상 및 비율 저장\n",
    "    color_ratios = {tuple(palette[i]): counter[i] / total_count for i in range(len(palette))}\n",
    "    # 색상명을 가져오도록 수정\n",
    "    color_list = [(get_color_name_from_rgb(*color), ratio) for color, ratio in color_ratios.items()]\n",
    "    \n",
    "    return sorted(color_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 🔹 밝기 및 대비 계산\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return np.std(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "# 🔹 전체 썸네일 분석 함수\n",
    "def analyze_image(image_url):\n",
    "    image, height, width = load_image_from_url(image_url)\n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    # Step 1: 이미지 특성 추출 (색상, 밝기, 대비)\n",
    "    colors = extract_colors(image)\n",
    "    brightness = calculate_brightness(image)\n",
    "    contrast = calculate_contrast(image)\n",
    "    \n",
    "    # Step 2: 이미지 전처리 후 OCR 텍스트 추출\n",
    "    processed_image = preprocess_image(image)\n",
    "    text_data = extract_text(processed_image, confidence_threshold=0.7)\n",
    "    \n",
    "    # Step 3: 객체 탐지 (YOLO)\n",
    "    object_data = detect_objects(image)\n",
    "    \n",
    "    # 결과 리턴\n",
    "    result = {\n",
    "        \"dominant_colors\": colors,\n",
    "        \"brightness\": brightness,\n",
    "        \"contrast\": contrast,\n",
    "        \"text_details\": text_data,\n",
    "        \"object_details\": object_data\n",
    "    }\n",
    "    \n",
    "    return result, height, width\n",
    "\n",
    "brightness_li=[]\n",
    "contrast_li=[]\n",
    "dominant_colors_li=[]\n",
    "text_details_li=[]\n",
    "largest_text_li=[]\n",
    "objects_details_li=[]\n",
    "thumbnail_size=[]\n",
    "\n",
    "for i in df['thumbnail_url']:\n",
    "    image_url = i\n",
    "    analysis_result, height, width = analyze_image(image_url)\n",
    "    thumbnail_size.append((height, width))\n",
    "    \n",
    "    brightness_li.append(analysis_result['brightness'])\n",
    "    contrast_li.append(analysis_result['contrast'])\n",
    "    dominant_colors_li.append(analysis_result['dominant_colors'])\n",
    "    text_details_li.append(analysis_result['text_details'])\n",
    "    objects_details_li.append(analysis_result['object_details']['objects'])\n",
    "\n",
    "df['brightness']=brightness_li\n",
    "df['contrast']=contrast_li\n",
    "df['dominant_colors']=dominant_colors_li\n",
    "df['text_details']=text_details_li\n",
    "df['objects_details']=objects_details_li\n",
    "df['thumbnail_size']=thumbnail_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa8b91d6-446b-49e1-a428-a77358b82392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_positions(image_width, image_height, text_details, object_details):\n",
    "    def classify_position(x, y, width, height):\n",
    "        \"\"\" 위치를 왼쪽/중간/오른쪽, 위/중간/아래, 크기별로 분류 \"\"\"\n",
    "        right_x = x + width\n",
    "        bottom_y = y + height\n",
    "\n",
    "        # 가로 위치 (left, middle, right)\n",
    "        if right_x < image_width * 0.33:\n",
    "            horizontal_position = \"left\"\n",
    "        elif x > image_width * 0.67:\n",
    "            horizontal_position = \"right\"\n",
    "        else:\n",
    "            horizontal_position = \"middle\"\n",
    "\n",
    "        # 세로 위치 (up, middle, down)\n",
    "        if bottom_y < image_height * 0.33:\n",
    "            vertical_position = \"up\"\n",
    "        elif y > image_height * 0.67:\n",
    "            vertical_position = \"down\"\n",
    "        else:\n",
    "            vertical_position = \"middle\"\n",
    "\n",
    "        # 크기 분류 (s, m, l)\n",
    "        area = width * height\n",
    "        size_category = \"s\" if area < 10000 else (\"m\" if area < 30000 else \"l\")\n",
    "\n",
    "        return f\"{horizontal_position} {vertical_position} {size_category}\"\n",
    "\n",
    "    # Text 위치 분석\n",
    "    text_positions = [classify_position(td['x'], td['y'], td['width'], td['height']) for td in text_details]\n",
    "    if not text_positions:  # 텍스트가 없을 경우\n",
    "        text_positions = [\"텍스트 없음\"]\n",
    "\n",
    "    # Person 위치 분석\n",
    "    person_positions = [\n",
    "        classify_position(obj['x'], obj['y'], obj['width'], obj['height'])\n",
    "        for obj in object_details if obj['label'] == 'person'\n",
    "    ]\n",
    "    if not person_positions:  # 사람 객체가 없을 경우\n",
    "        person_positions = [\"사람 없음\"]\n",
    "\n",
    "    # 신뢰도 높은 텍스트 추출 (probability ≥ 0.7)\n",
    "    high_confidence_texts = [td[\"text\"] for td in text_details if td.get(\"probability\", 0) >= 0.7]\n",
    "    prob_text = high_confidence_texts if high_confidence_texts else [\"해당 없음\"]\n",
    "\n",
    "    return text_positions, person_positions, prob_text\n",
    "\n",
    "\n",
    "df[[\"text_positions\", \"person_positions\", \"prob_text\"]] = df.apply(\n",
    "    lambda row: pd.Series(\n",
    "        classify_positions(\n",
    "            image_width=width,  # 이미지 가로 크기\n",
    "            image_height=height,  # 이미지 세로 크기\n",
    "            text_details=row[\"text_details\"],\n",
    "            object_details=row[\"objects_details\"]\n",
    "        )\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "262df99d-0653-4ffd-9ea9-13b42d8df3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_li=[]\n",
    "for i in df['objects_details']:\n",
    "    object_li=[]\n",
    "    for j in i:\n",
    "        object_li.append(j['label'])\n",
    "    objects_li.append(object_li)\n",
    "\n",
    "assert len(df) == len(objects_li), \"Length of text_position_li does not match the number of rows in df\"\n",
    "df['contain_object'] = objects_li\n",
    "\n",
    "del df['text_details']\n",
    "del df['objects_details']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cc98f7-433c-4d31-bb3b-ea14352e651c",
   "metadata": {},
   "source": [
    "## 제목"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3c85e-e0a6-43cc-a915-0ebd4cfbd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# KoNLPy의 Okt 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 불용어 리스트 (영어 불용어 및 한글 불용어)\n",
    "stopwords_korean = [\n",
    "    '이', '그', '저', '그리고', '하지만', '그래서', '또는', '왜', '어떻게', '나', '너', '저희', '우리', '그녀', '그의', \n",
    "    '그들', '같은', '많은', '다', '좀', '그렇지만', '여기', '거기', '이것', '그것', '이야', '할', '지금', '시간', '것', \n",
    "    '수', '같이', '되다', '하다', '있다', '없다', '위해', '왜냐하면', '하기', '까지', '좀', '나중에'\n",
    "]\n",
    "stopwords_english = [\n",
    "    'the', 'and', 'a', 'an', 'in', 'on', 'at', 'for', 'with', 'about', 'as', 'by', 'of', 'to', 'from', 'that', 'which', \n",
    "    'who', 'whom', 'this', 'it', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'has', 'have', 'had', 'having', 'do', \n",
    "    'does', 'did', 'doing', 'doing', 'themselves', 'yours', 'ours', 'its', 'their', 'theirs', 'what', 'how', 'why', 'where', \n",
    "    'when', 'i', 'you', 'he', 'she', 'we', 'they', 'all', 'any', 'one', 'some', 'each', 'every', 'no', 'not', 'nor', 'only', \n",
    "    'own', 'same', 'so', 'than', 'too', 'very', 'just', 'don’t', 'should', 'now', 'up', 'down', 'here', 'there', 'when', \n",
    "    'where', 'why'\n",
    "]\n",
    "# 감성 분석을 위한 SentimentIntensityAnalyzer 초기화\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 텍스트 전처리 함수 (특수문자 제거 및 소문자 변환)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 특수문자 제거\n",
    "    return text.lower()\n",
    "\n",
    "# 제목 길이 계산\n",
    "def calculate_title_length(title):\n",
    "    return len(title)\n",
    "\n",
    "# 감성 분석 함수\n",
    "def sentiment_analysis(title):\n",
    "    sentiment_score = analyzer.polarity_scores(title)\n",
    "    sentiment = 'positive' if sentiment_score['compound'] > 0 else 'negative' if sentiment_score['compound'] < 0 else 'neutral'\n",
    "    return sentiment\n",
    "\n",
    "# 이모티콘 포함 여부 확인\n",
    "def contains_emoji(title):\n",
    "    return any(emoji.is_emoji(char) for char in title)\n",
    "\n",
    "def count_emojis(title):\n",
    "    return sum(1 for char in title if emoji.is_emoji(char))\n",
    "\n",
    "# 특수문자 포함 여부 확인\n",
    "def contains_special_characters(title):\n",
    "    return bool(re.search(r'[^\\w\\s]', title))\n",
    "\n",
    "# 핵심 키워드 추출 함수 (KoNLPy를 사용한 명사 추출)\n",
    "def extract_keywords_korean(title):\n",
    "    nouns = okt.nouns(title)  # 명사만 추출\n",
    "    filtered_nouns = [word for word in nouns if word not in stopwords_korean and word not in stopwords_english]\n",
    "    \n",
    "    if not filtered_nouns:  # 만약 필터링된 명사가 없다면 빈 리스트를 반환\n",
    "        return []\n",
    "    \n",
    "    # 단어 빈도 계산\n",
    "    vectorizer = CountVectorizer(stop_words=None, ngram_range=(1, 1))  # 1-gram만 추출\n",
    "    X = vectorizer.fit_transform([' '.join(filtered_nouns)])\n",
    "    word_freq = dict(zip(vectorizer.get_feature_names_out(), X.toarray().flatten()))\n",
    "    \n",
    "    # 상위 3개 키워드 추출\n",
    "    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, freq in sorted_words[:3]]\n",
    "\n",
    "# 전체 피쳐 추출 함수\n",
    "def extract_features_from_titles(df):\n",
    "    features = []\n",
    "    for title in df['title']:  # DataFrame에서 제목을 하나씩 처리\n",
    "        preprocessed_title = preprocess_text(title)\n",
    "        title_length = calculate_title_length(title)\n",
    "        sentiment = sentiment_analysis(title)\n",
    "        has_emoji = contains_emoji(title)\n",
    "        count_emoji = count_emojis(title)\n",
    "        has_special_characters = contains_special_characters(title)\n",
    "        keywords = extract_keywords_korean(preprocessed_title)\n",
    "        \n",
    "        # 추출된 피쳐들\n",
    "        features.append({\n",
    "            'title': title,\n",
    "            'title_length': title_length,\n",
    "            'sentiment': sentiment,\n",
    "            'has_emoji': has_emoji,\n",
    "            'emoji_count': count_emoji, \n",
    "            'has_special_characters': has_special_characters,\n",
    "            'keywords': keywords\n",
    "        })\n",
    "    \n",
    "    # 피쳐들을 DataFrame으로 변환\n",
    "    feature_df = pd.DataFrame(features)\n",
    "    return feature_df\n",
    "\n",
    "# 피쳐 추출\n",
    "feature_df = extract_features_from_titles(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
