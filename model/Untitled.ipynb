{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d88c4ac-906d-409d-8aa3-266248b32254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Using cache found in C:\\Users\\duwjd/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-4-24 Python-3.11.7 torch-2.7.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\duwjd/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11.883536\n",
      "Name: predicted_views, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duwjd\\AppData\\Local\\Temp\\ipykernel_820\\3745093418.py:497: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['predicted_views'] = y_pred\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch  # YOLOv5는 PyTorch로 구현됨\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "import webcolors\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from konlpy.tag import Okt\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "# 사용자 입력 받기\n",
    "title = '저 드디어 강남에 샵 오픈했어요😭취향 가득 담은 제 샵을 소개합니다🤍 | 인테리어 브이로그 | 반셀프 인테리어 | 뷰티샵 인테리어 | 재유JEYU'\n",
    "thumbnail_url = 'https://i.ytimg.com/vi/IbxI43fHWnk/maxresdefault.jpg'\n",
    "duration = '08:30'\n",
    "subscriber_count = 200000\n",
    "\n",
    "# 현재 시간 기준으로 pub_year, pub_month, pub_weekday 구하기\n",
    "current_time = datetime.now()\n",
    "pub_year = current_time.year\n",
    "pub_month = current_time.month\n",
    "pub_weekday = current_time.weekday()  # 월요일=0, 일요일=6\n",
    "\n",
    "# 입력받은 데이터를 dictionary로 저장\n",
    "data = {\n",
    "    \"title\": title,\n",
    "    \"thumbnail_url\": thumbnail_url,\n",
    "    \"duration\": duration,\n",
    "    \"subscriber_count\": subscriber_count,\n",
    "    \"pub_year\": pub_year,\n",
    "    \"pub_month\": pub_month,\n",
    "    \"pub_weekday\": pub_weekday\n",
    "}\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# OCR Reader 설정\n",
    "ocr_reader = easyocr.Reader(['en', 'ko'])  # 영어 & 한글 OCR 지원\n",
    "\n",
    "def convert_duration_to_minutes(duration_str):\n",
    "    try:\n",
    "        hours, minutes = map(int, duration_str.split(\":\"))\n",
    "        return hours * 60 + minutes\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting duration: {e}\")\n",
    "        return 0\n",
    "\n",
    "# 'duration' 컬럼을 분으로 변환\n",
    "df['duration'] = df['duration'].apply(convert_duration_to_minutes)\n",
    "\n",
    "# 이미지 로드 (URL에서 다운로드)\n",
    "def load_image_from_url(url):\n",
    "    fallback_urls = [\n",
    "        url,\n",
    "        url.replace('maxresdefault', 'sddefault'),\n",
    "        url.replace('sddefault', 'hqdefault'),\n",
    "        url.replace('hqdefault', 'mqdefault'),\n",
    "        url.replace('mqdefault', 'default')\n",
    "    ]\n",
    "\n",
    "    for new_url in fallback_urls:\n",
    "        try:\n",
    "            response = requests.get(new_url, stream=True, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            image = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            if image is not None:\n",
    "                height, width, _ = image.shape\n",
    "                return image, height, width\n",
    "        except requests.RequestException:\n",
    "            print(f\"이미지 로드 실패: {new_url}\")\n",
    "\n",
    "    raise ValueError(\"모든 URL에서 이미지를 불러올 수 없습니다.\")\n",
    "\n",
    "# 이미지 전처리 (그레이스케일 + 이진화)\n",
    "def preprocess_image(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    denoised_image = cv2.GaussianBlur(binary_image, (5, 5), 0)\n",
    "    return denoised_image\n",
    "\n",
    "# 텍스트 분석 (OCR)\n",
    "def extract_text(image, confidence_threshold=0.7):\n",
    "    results = ocr_reader.readtext(image)\n",
    "    text_info = []\n",
    "    for (bbox, text, prob) in results:\n",
    "        if prob >= confidence_threshold:\n",
    "            (top_left, _, bottom_right, _) = bbox\n",
    "            x, y = int(top_left[0]), int(top_left[1])\n",
    "            width = int(bottom_right[0] - top_left[0])\n",
    "            height = int(bottom_right[1] - top_left[1])\n",
    "            area = width * height\n",
    "            \n",
    "            text_info.append({\n",
    "                \"text\": text,\n",
    "                \"x\": x, \"y\": y,\n",
    "                \"width\": width, \"height\": height,\n",
    "                \"area\": area,\n",
    "                \"probability\": prob\n",
    "            })\n",
    "    return text_info\n",
    "\n",
    "# YOLOv5 모델 로드 (PyTorch Hub)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # 'yolov5s'는 작은 모델 (빠름)\n",
    "\n",
    "# 객체 탐지 (YOLOv5)\n",
    "def detect_objects_with_yolov5(image):\n",
    "    if image is None:\n",
    "        return {\"objects\": [], \"central_focus\": False}\n",
    "    \n",
    "    # YOLOv5 모델을 사용하여 객체 감지\n",
    "    results = model(image)  # 이미지에서 객체 감지\n",
    "    objects = []\n",
    "    central_focus = False\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # 감지된 객체들\n",
    "    for det in results.xywh[0].cpu().numpy():  # 결과는 (x_center, y_center, width, height, confidence, class) 형식\n",
    "        x_center, y_center, w, h, conf, cls = det\n",
    "        if conf > 0.5:  # confidence score가 0.5 이상인 객체만 사용\n",
    "            label = results.names[int(cls)]  # 객체의 클래스 이름 (예: 'person', 'car', etc.)\n",
    "            x1 = int((x_center - w / 2) * width)\n",
    "            y1 = int((y_center - h / 2) * height)\n",
    "            x2 = int((x_center + w / 2) * width)\n",
    "            y2 = int((y_center + h / 2) * height)\n",
    "            objects.append({\"label\": label, \"x\": x1, \"y\": y1, \"width\": x2 - x1, \"height\": y2 - y1})\n",
    "            \n",
    "            # 중앙에 가까운지 확인\n",
    "            if (width * 0.3) < x_center < (width * 0.7) and (height * 0.3) < y_center < (height * 0.7):\n",
    "                central_focus = True\n",
    "    \n",
    "    # 감지된 객체와 중앙에 있는지 여부 리턴\n",
    "    return {\"objects\": objects, \"central_focus\": central_focus}\n",
    "\n",
    "# 주요 색상 추출 및 이름 변환\n",
    "def closest_colour(requested_colour):\n",
    "    \"\"\"주어진 RGB 값과 가장 가까운 CSS3 색상명을 찾음\"\"\"\n",
    "    min_colours = {}\n",
    "    for name in webcolors.names(\"css3\"):\n",
    "        r_c, g_c, b_c = webcolors.name_to_rgb(name)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "\n",
    "def get_color_name_from_rgb(r, g, b):\n",
    "    \"\"\"정확한 색상이 있으면 반환, 없으면 가장 가까운 색상명 반환\"\"\"\n",
    "    try:\n",
    "        return webcolors.rgb_to_name((r, g, b), spec='css3')\n",
    "    except ValueError:\n",
    "        return closest_colour((r, g, b))\n",
    "\n",
    "def extract_colors(image, num_colors=3):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).reshape((-1, 3))\n",
    "    kmeans = KMeans(n_clusters=num_colors, n_init=\"auto\")\n",
    "    labels = kmeans.fit_predict(image)\n",
    "    palette = kmeans.cluster_centers_.astype(int)\n",
    "    \n",
    "    # 색상의 출현 빈도 계산\n",
    "    counter = np.bincount(labels)\n",
    "    total_count = np.sum(counter)\n",
    "    # 주요 색상 및 비율 저장\n",
    "    color_ratios = {tuple(palette[i]): counter[i] / total_count for i in range(len(palette))}\n",
    "    # 색상명을 가져오도록 수정\n",
    "    color_list = [(get_color_name_from_rgb(*color), ratio) for color, ratio in color_ratios.items()]\n",
    "    \n",
    "    return sorted(color_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 밝기 및 대비 계산\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return np.std(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "# 썸네일 분석 함수\n",
    "def analyze_image(image_url):\n",
    "    image, height, width = load_image_from_url(image_url)\n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    # Step 1: 이미지 특성 추출 (색상, 밝기, 대비)\n",
    "    colors = extract_colors(image)\n",
    "    brightness = calculate_brightness(image)\n",
    "    contrast = calculate_contrast(image)\n",
    "    \n",
    "    # Step 2: 이미지 전처리 후 OCR 텍스트 추출\n",
    "    processed_image = preprocess_image(image)\n",
    "    text_data = extract_text(processed_image, confidence_threshold=0.7)\n",
    "    \n",
    "    # Step 3: 객체 탐지 (YOLOv5)\n",
    "    object_data = detect_objects_with_yolov5(image)\n",
    "    \n",
    "    # 결과 리턴\n",
    "    result = {\n",
    "        \"dominant_colors\": colors,\n",
    "        \"brightness\": brightness,\n",
    "        \"contrast\": contrast,\n",
    "        \"text_details\": text_data,\n",
    "        \"object_details\": object_data\n",
    "    }\n",
    "    \n",
    "    return result, height, width\n",
    "\n",
    "# Get the size of the thumbnail image (width, height)\n",
    "def get_thumbnail_size(url):\n",
    "    image, height, width = load_image_from_url(url)\n",
    "    return (height, width) if image is not None else (None, None)\n",
    "\n",
    "# Add 'thumbnail_size' column\n",
    "df['thumbnail_size'] = df['thumbnail_url'].apply(get_thumbnail_size)\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 불용어 리스트\n",
    "stopwords = set([\n",
    "    '은', '는', '이', '가', '을', '를', '에', '의', '도', '로', '과', '와', '한', '하다',\n",
    "    '에서', '에게', '까지', '부터', '보다', '처럼', '만', '없이', '수', '것', '좀', '더', '이',\n",
    "    '또', '등', '그', '이것', '저것', '그것', '거', '때', '건', '중', '나', '너', '저', '우리',\n",
    "    '누구', '뭐', '왜', '어디', '어떻게', '영상', '채널', '오늘', '이제', '정말', '진짜',\n",
    "    '완전', '그냥', '내가', '당신', '내용', '제목', '시작', '끝', '다시', '모두',\n",
    "    '최고', '대박', '소름', '헐', 'ㅋㅋ', 'ㅎㅎ', 'ㅠㅠ', '와우','자막','브이','로그','일상',\n",
    "    '정보', '필독', '업로드', '자막', '구독', '좋아요', '댓글', '시청', '확인',\n",
    "    '보세요'\n",
    "])\n",
    "\n",
    "# 클릭 유도 키워드\n",
    "clickbait_keywords = [\n",
    "    '실화', '충격', '대박', '소름', '반전', '최초', '드디어', '헐', '진실',\n",
    "    '믿기지', '이게', '무조건', '죽기 전에', '꼭 봐야할'\n",
    "]\n",
    "\n",
    "# 피처 추출 함수\n",
    "def extract_korean_title_features(title, video_id):\n",
    "    features = {}\n",
    "    features['video_id'] = video_id\n",
    "    features['title'] = title\n",
    "    features['title_length'] = len(title)\n",
    "    features['word_count'] = len(okt.morphs(title))\n",
    "\n",
    "    # 이모지 관련 피처\n",
    "    features['emoji_count'] = sum(1 for char in title if char in emoji.EMOJI_DATA)\n",
    "    features['has_emoji'] = int(features['emoji_count'] > 0)\n",
    "\n",
    "    # 특수문자 수\n",
    "    special_chars = re.findall(r\"[!\\\"#$%&'()*+,\\-./:;<=>?@\\[\\]^_`{|}~]\", title)\n",
    "    features['special_char_count'] = len(special_chars)\n",
    "\n",
    "    # 클릭 유도 키워드 포함 여부\n",
    "    features['is_clickbait'] = int(any(word in title for word in clickbait_keywords))\n",
    "\n",
    "    # 구두점 포함 여부\n",
    "    features['has_question_mark'] = '?' in title\n",
    "    features['has_exclamation'] = '!' in title\n",
    "\n",
    "    # 주요 명사 3개 추출 (불용어 제거 포함)\n",
    "    nouns = okt.nouns(title)\n",
    "    filtered_nouns = [noun for noun in nouns if noun not in stopwords and len(noun) > 1]\n",
    "    noun_freq = Counter(filtered_nouns)\n",
    "    top_nouns = [word for word, _ in noun_freq.most_common(3)]\n",
    "    for i in range(3):\n",
    "        features[f'top_noun_{i+1}'] = top_nouns[i] if i < len(top_nouns) else ''\n",
    "\n",
    "    return features\n",
    "\n",
    "# Extract features from title and thumbnail\n",
    "title_features = extract_korean_title_features(df.iloc[0, 0], '0')\n",
    "thumbnail_features, height, width = analyze_image(df.iloc[0, 1])\n",
    "\n",
    "# Add features to the DataFrame\n",
    "# Title features\n",
    "for key, value in title_features.items():\n",
    "    df[key] = value\n",
    "\n",
    "# Thumbnail features (dominant_colors, brightness, contrast, etc.)\n",
    "df['dominant_colors'] = [', '.join([color[0] for color in thumbnail_features['dominant_colors']])]\n",
    "\n",
    "df['brightness'] = thumbnail_features['brightness']\n",
    "df['contrast'] = thumbnail_features['contrast']\n",
    "df['text_details'] = [thumbnail_features['text_details']]  # Keep the structure intact for text details\n",
    "df['object_details'] = [thumbnail_features['object_details']]  # Keep the structure intact for object details\n",
    "\n",
    "def classify_positions(image_width, image_height, text_details, object_details):\n",
    "    def classify_position(x, y, width, height):\n",
    "        \"\"\" 위치를 왼쪽/중간/오른쪽, 위/중간/아래, 크기별로 분류 \"\"\"\n",
    "        right_x = x + width\n",
    "        bottom_y = y + height\n",
    "\n",
    "        # 가로 위치 (left, middle, right)\n",
    "        if right_x < image_width * 0.33:\n",
    "            horizontal_position = \"left\"\n",
    "        elif x > image_width * 0.67:\n",
    "            horizontal_position = \"right\"\n",
    "        else:\n",
    "            horizontal_position = \"middle\"\n",
    "\n",
    "        # 세로 위치 (up, middle, down)\n",
    "        if bottom_y < image_height * 0.33:\n",
    "            vertical_position = \"up\"\n",
    "        elif y > image_height * 0.67:\n",
    "            vertical_position = \"down\"\n",
    "        else:\n",
    "            vertical_position = \"middle\"\n",
    "\n",
    "        # 크기 분류 (s, m, l)\n",
    "        area = width * height\n",
    "        size_category = \"s\" if area < 10000 else (\"m\" if area < 30000 else \"l\")\n",
    "\n",
    "        return f\"{horizontal_position} {vertical_position} {size_category}\"\n",
    "\n",
    "    # 텍스트 위치 분석\n",
    "    text_positions = [classify_position(td['x'], td['y'], td['width'], td['height']) for td in text_details]\n",
    "    if not text_positions:  # 텍스트가 없을 경우\n",
    "        text_positions = [\"텍스트 없음\"]\n",
    "\n",
    "    # 사람 위치 분석\n",
    "    person_positions = []\n",
    "    \n",
    "    # Ensure 'object_details' is a dictionary and contains 'objects' key\n",
    "    if isinstance(object_details, dict) and 'objects' in object_details:\n",
    "        for obj in object_details['objects']:\n",
    "            if isinstance(obj, dict) and obj.get('label') == 'person':\n",
    "                # 'person' 객체만 위치 분류\n",
    "                position = classify_position(obj['x'], obj['y'], obj['width'], obj['height'])\n",
    "                person_positions.append(position)\n",
    "\n",
    "    if not person_positions:  # 사람 객체가 없을 경우\n",
    "        person_positions = [\"사람 없음\"]\n",
    "\n",
    "    # 신뢰도 높은 텍스트 추출 (probability ≥ 0.7)\n",
    "    high_confidence_texts = [td[\"text\"] for td in text_details if td.get(\"probability\", 0) >= 0.7]\n",
    "    prob_text = high_confidence_texts if high_confidence_texts else [\"해당 없음\"]\n",
    "\n",
    "    return text_positions, person_positions, prob_text\n",
    "\n",
    "\n",
    "# Apply the function to classify text and person positions\n",
    "df[[\"text_positions\", \"person_positions\", \"prob_text\"]] = df.apply(\n",
    "    lambda row: pd.Series(\n",
    "        classify_positions(\n",
    "            image_width=row[\"thumbnail_size\"][1],   # width (두 번째 요소)\n",
    "            image_height=row[\"thumbnail_size\"][0],  # height (첫 번째 요소)\n",
    "            text_details=ast.literal_eval(row[\"text_details\"]) if isinstance(row[\"text_details\"], str) else row[\"text_details\"],\n",
    "            object_details=ast.literal_eval(row[\"object_details\"]) if isinstance(row[\"object_details\"], str) else row[\"object_details\"]\n",
    "        )\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Ensure that 'person_positions' is a list, if it's a string, convert it to list\n",
    "df['person_positions'] = df['person_positions'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "def extract_labels(obj_detail_str):\n",
    "    try:\n",
    "        # If obj_detail_str is a string, convert it to a dictionary\n",
    "        obj_details = ast.literal_eval(obj_detail_str) if isinstance(obj_detail_str, str) else obj_detail_str\n",
    "        \n",
    "        # Check if the 'objects' key exists and it contains a list\n",
    "        if isinstance(obj_details, dict) and 'objects' in obj_details and isinstance(obj_details['objects'], list):\n",
    "            # Extract labels from the objects list\n",
    "            labels = [obj[\"label\"] for obj in obj_details['objects'] if \"label\" in obj]\n",
    "            return labels if labels else [\"없음\"]\n",
    "        else:\n",
    "            return [\"에러\"]\n",
    "    except Exception as e:\n",
    "        # Handle any errors (e.g., invalid format, missing 'objects' key)\n",
    "        print(f\"Error extracting labels: {e}\")\n",
    "        return [\"에러\"]\n",
    "\n",
    "df[\"object_labels\"] = df[\"object_details\"].apply(extract_labels)\n",
    "\n",
    "\n",
    "# 문자열을 실제 리스트로 변환 (object_labels 칼럼에만 적용)\n",
    "df['object_labels'] = df['object_labels'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    return val if isinstance(val, list) else []\n",
    "\n",
    "df['person_count'] = df['object_labels'].apply(lambda x: x.count('person') if isinstance(x, list) else 0)\n",
    "df['object_count'] = df['object_labels'].apply(lambda x: len([obj for obj in x if obj != 'person']) if isinstance(x, list) else 0)\n",
    "\n",
    "df['has_text'] = df['text_positions'].apply(lambda x: int(x != ['텍스트 없음']))\n",
    "\n",
    "# 사람 위치\n",
    "df['person_left'] = df['person_positions'].apply(lambda x: sum('left' in p for p in x))\n",
    "df['person_middle'] = df['person_positions'].apply(lambda x: sum('middle' in p for p in x))\n",
    "df['person_right'] = df['person_positions'].apply(lambda x: sum('right' in p for p in x))\n",
    "df['person_small'] = df['person_positions'].apply(lambda x: sum('s' in p for p in x))\n",
    "df['person_medium'] = df['person_positions'].apply(lambda x: sum('m' in p for p in x))\n",
    "df['person_large'] = df['person_positions'].apply(lambda x: sum('l' in p for p in x))\n",
    "\n",
    "# 텍스트 위치\n",
    "df['text_left'] = df['text_positions'].apply(lambda x: sum('left' in p for p in x))\n",
    "df['text_middle'] = df['text_positions'].apply(lambda x: sum('middle' in p for p in x))\n",
    "df['text_right'] = df['text_positions'].apply(lambda x: sum('right' in p for p in x))\n",
    "df['text_small'] = df['text_positions'].apply(lambda x: sum('s' in p for p in x))\n",
    "df['text_medium'] = df['text_positions'].apply(lambda x: sum('m' in p for p in x))\n",
    "df['text_large'] = df['text_positions'].apply(lambda x: sum('l' in p for p in x))\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import webcolors\n",
    "\n",
    "# 웹 색상 이름을 기반으로 한 더 광범위한 색상 그룹 설정\n",
    "color_groups = {\n",
    "    'red': {'red', 'crimson', 'firebrick', 'darkred', 'salmon', 'indianred', 'tomato', 'orangered', 'darkorange', 'lightcoral', 'maroon', 'brown'},\n",
    "    'blue': {'blue', 'navy', 'dodgerblue', 'deepskyblue', 'royalblue', 'skyblue', 'slateblue', 'mediumblue', 'cornflowerblue', 'steelblue', 'lightblue', 'powderblue', 'midnightblue', 'lightsteelblue'},\n",
    "    'green': {'green', 'lime', 'forestgreen', 'seagreen', 'springgreen', 'mediumseagreen', 'darkgreen', 'lawngreen', 'yellowgreen', 'olive', 'olivedrab', 'chartreuse'},\n",
    "    'yellow': {'yellow', 'gold', 'khaki', 'lemonchiffon', 'lightyellow', 'palegoldenrod', 'lightgoldenrodyellow', 'goldenrod', 'darkgoldenrod'},\n",
    "    'purple': {'purple', 'magenta', 'violet', 'orchid', 'mediumorchid', 'mediumpurple', 'darkviolet', 'blueviolet', 'darkorchid', 'thistle', 'lavender', 'plum'},\n",
    "    'brown': {'brown', 'sienna', 'chocolate', 'peru', 'saddlebrown', 'tan', 'burlywood', 'rosybrown', 'darkkhaki', 'khaki'},\n",
    "    'grey': {'grey', 'gray', 'lightgrey', 'darkgrey', 'dimgrey', 'slategrey', 'gainsboro', 'darkslategrey', 'lightsteelblue', 'silver', 'dimgray'},\n",
    "    'white': {'white', 'snow', 'ivory', 'ghostwhite', 'whitesmoke', 'floralwhite', 'seashell', 'beige', 'linen', 'mintcream', 'seashell'},\n",
    "    'pink': {'pink', 'lightpink', 'hotpink', 'lavenderblush', 'deeppink', 'mediumvioletred', 'palevioletred'},\n",
    "    'black': {'black', 'darkslategray', 'dimgray', 'charcoal'},\n",
    "    'other': set()\n",
    "}\n",
    "\n",
    "# 색상을 그룹으로 매핑\n",
    "def map_color_to_group(color):\n",
    "    for group, colors in color_groups.items():\n",
    "        if color.lower() in colors:\n",
    "            return group\n",
    "    return 'other'\n",
    "\n",
    "# 각 색상 그룹별로 0.0 초기화\n",
    "for col in color_groups.keys():\n",
    "    df[f'color_{col}'] = 0.0\n",
    "\n",
    "# 색상 그룹 확률을 계산하는 함수\n",
    "def count_color_groups(color_list):\n",
    "    counter = defaultdict(float)\n",
    "    for color in color_list:\n",
    "        group = map_color_to_group(color)\n",
    "        counter[group] += 1  # 각 색상은 1씩 추가됨\n",
    "    return counter\n",
    "\n",
    "# dominant_colors 컬럼이 문자열로 되어있으므로, 이를 리스트로 변환\n",
    "for idx, row in df.iterrows():\n",
    "    if isinstance(row['dominant_colors'], str):\n",
    "        color_list = row['dominant_colors'].split(', ')  # ',' 기준으로 분할하여 리스트로 변환\n",
    "        counter = count_color_groups(color_list)\n",
    "        for group in counter:\n",
    "            df.at[idx, f'color_{group}'] = counter[group]\n",
    "\n",
    "# 색상 컬럼이 0이면 0, 0이 아니면 1로 변환\n",
    "color_columns = [\n",
    "    'color_red', 'color_blue', 'color_green', 'color_yellow',\n",
    "    'color_purple', 'color_brown', 'color_grey', 'color_white',\n",
    "    'color_pink', 'color_black', 'color_other'\n",
    "]\n",
    "\n",
    "df[color_columns] = df[color_columns].applymap(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "feature_cols = [\n",
    "    'duration', 'subscriber_count', 'brightness', 'contrast',\n",
    "       'title_length', 'word_count', 'emoji_count', 'has_emoji',\n",
    "       'special_char_count', 'is_clickbait', 'has_question_mark',\n",
    "       'has_exclamation', 'pub_year', 'pub_month', 'pub_weekday', 'color_red',\n",
    "       'color_blue', 'color_green', 'color_yellow', 'color_purple',\n",
    "       'color_brown', 'color_grey', 'color_white', 'color_pink',\n",
    "       'person_count', 'object_count', 'has_text', 'person_left',\n",
    "       'person_middle', 'person_right', 'person_small', 'person_medium',\n",
    "       'person_large', 'text_left', 'text_middle', 'text_right', 'text_small',\n",
    "       'text_medium', 'text_large'\n",
    "]\n",
    "model_df=df[feature_cols]\n",
    "\n",
    "\n",
    "\n",
    "import joblib  # or use pickle if you prefer\n",
    "\n",
    "# 모델 로드 (예: RandomForest, XGBoost, LinearRegression 등)\n",
    "model = joblib.load('saved_models/model_cluster_0.pkl')\n",
    "# 예측에 필요한 특성만 선택 (모델 학습에 사용한 특성과 동일해야 함)\n",
    "X = model_df[feature_cols]  # 특성들이 담긴 DataFrame\n",
    "# 예측 수행\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# 예측 결과를 DataFrame에 추가\n",
    "model_df['predicted_views'] = y_pred\n",
    "# 예측 결과 출력\n",
    "print(model_df['predicted_views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d288696b-5b7b-4eff-a9a5-2a879ba0b922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duwjd\\AppData\\Local\\Temp\\ipykernel_820\\4124645825.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['subscriber_count']=100000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10.027542\n",
      "Name: predicted_views, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duwjd\\AppData\\Local\\Temp\\ipykernel_820\\4124645825.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['predicted_views'] = y_pred\n"
     ]
    }
   ],
   "source": [
    "import joblib  # or use pickle if you prefer\n",
    "model_df['subscriber_count']=100000000\n",
    "# 모델 로드 (예: RandomForest, XGBoost, LinearRegression 등)\n",
    "model = joblib.load('saved_models/model_cluster_3.pkl')\n",
    "# 예측에 필요한 특성만 선택 (모델 학습에 사용한 특성과 동일해야 함)\n",
    "X = model_df[feature_cols]  # 특성들이 담긴 DataFrame\n",
    "# 예측 수행\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# 예측 결과를 DataFrame에 추가\n",
    "model_df['predicted_views'] = y_pred\n",
    "# 예측 결과 출력\n",
    "print(model_df['predicted_views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329b46d-3813-4a4a-bc6d-cfbd4543a04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
